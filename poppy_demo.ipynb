{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f866f5b2",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3c837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PoPPy folder with necessary directories is in folder PoPPy, but if you want you can clobe the original repo\n",
    "\n",
    "#!git clone https://github.com/HongtengXu/PoPPy.git\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "os.chdir('PoPPy')\n",
    "import dev.util as util\n",
    "from model.MixHawkesProcess import MixHawkesProcessModel\n",
    "from preprocess.DataIO import load_sequences_csv\n",
    "from preprocess.DataOperation import data_info, EventSampler, enumerate_all_events\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6f6b6b",
   "metadata": {},
   "source": [
    "### Loading Data\n",
    "\n",
    "Loading dataset, building dataframe with all files, loading dataset with true clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1fc2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = 'data/'\n",
    "dataset_name = 'IPTV'\n",
    "path_to_dataset = path_to_data+dataset_name\n",
    "\n",
    "df = pd.DataFrame([])\n",
    "\n",
    "all_files_in_datafolder = os.listdir(path_to_dataset)\n",
    "\n",
    "for file in all_files_in_datafolder:\n",
    "    \n",
    "    #skipping not relevant files \n",
    "    if file == 'all_users.csv' or file == 'info.json' or '(' in file:\n",
    "        continue\n",
    "        \n",
    "    elif file == 'clusters.csv': \n",
    "        # getting dataset with true labels\n",
    "        true_clust = pd.read_csv(f'{path_to_dataset}/clusters.csv') \n",
    "        true_clust.columns = ['file_name', true_clust.columns[1]]\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    df_loc = pd.read_csv(f'{path_to_dataset}/{file}')\n",
    "    df_loc['file_name'] = [int(file.replace('.csv', ''))] * len(df_loc)\n",
    "    df_loc = df_loc.iloc[:, 1:]\n",
    "    \n",
    "    df = pd.concat([df, df_loc])\n",
    "    \n",
    "df.to_csv(f'{path_to_dataset}/all_users.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ff067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "true_clust.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a76478f",
   "metadata": {},
   "source": [
    "### DataLoader\n",
    "\n",
    "Using dataloader from PoPPy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b3cd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "num_cluster = true_clust['cluster_id'].nunique() \n",
    "memory_size = 3\n",
    "batch_size = 128\n",
    "use_cuda = True\n",
    "use_cuda = use_cuda and torch.cuda.is_available()\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3d923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test sequence loading functions\n",
    "# load event sequences from csv file\n",
    "\n",
    "domain_names = {'seq_id': 'id',  # in this dict necessary to enter names of columns of your dataset appropriate id, time and event\n",
    "                'time': 'time',\n",
    "                'event': 'event'} \n",
    "database = load_sequences_csv(f'{path_to_dataset}/all_users.csv', #path do dataset with ids in one file\n",
    "                              domain_names=domain_names)\n",
    "data_info(database)\n",
    "\n",
    "# sample batches from database\n",
    "trainloader = DataLoader(EventSampler(database=database, memorysize=memory_size),\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True,\n",
    "                         **kwargs)\n",
    "validloader = DataLoader(EventSampler(database=database, memorysize=memory_size),\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True,\n",
    "                         **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fe7d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "num_type = len(database['type2idx'])\n",
    "mu_dict = {'model_name': 'NaiveExogenousIntensity',\n",
    "           'parameter_set': {'activation': 'identity'}\n",
    "           }\n",
    "alpha_dict = {'model_name': 'NaiveEndogenousImpact',\n",
    "              'parameter_set': {'activation': 'identity'}\n",
    "              }\n",
    "\n",
    "kernel_para = np.zeros((2, 1))\n",
    "kernel_para[1, 0] = 0.5\n",
    "kernel_para = torch.from_numpy(kernel_para)\n",
    "kernel_para = kernel_para.type(torch.FloatTensor)\n",
    "kernel_dict = {'model_name': 'GateKernel',\n",
    "               'parameter_set': kernel_para}\n",
    "mixhawkes_model = MixHawkesProcessModel(num_type=num_type,\n",
    "                                        num_cluster=num_cluster,\n",
    "                                        num_sequence=len(database['seq2idx']),\n",
    "                                        mu_dict=[mu_dict],\n",
    "                                        alpha_dict=[alpha_dict],\n",
    "                                        kernel_dict=[kernel_dict],\n",
    "                                        activation='identity',\n",
    "                                        use_cuda=use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be783d0",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604d7cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize optimizer\n",
    "optimizer = optim.Adam(mixhawkes_model.lambda_model.parameters(), lr=0.01)\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.8)\n",
    "\n",
    "# train model\n",
    "mixhawkes_model.fit(trainloader, optimizer, epochs, scheduler=scheduler,\n",
    "                    sparsity=100, nonnegative=0, use_cuda=use_cuda, validation_set=validloader)\n",
    "# save model\n",
    "mixhawkes_model.save_model('PoPPy/{}/DMHP_1.pt'.format(util.OUTPUT_DIR), mode='entire')\n",
    "mixhawkes_model.save_model('PoPPy/{}/DMHP_1.pt'.format(util.OUTPUT_DIR), mode='parameter')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8797738c",
   "metadata": {},
   "source": [
    "### Predicting clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d49869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model (works only if CUDA is avaliable: odd things from PoPPy repo)\n",
    "mixhawkes_model.load_model(f'PoPPy/{util.OUTPUT_DIR}/DMHP_1.pt', mode='entire')\n",
    "r = mixhawkes_model.responsibility\n",
    "clusters_prediction = np.argmax(r.detach().cpu().numpy(), axis=1) # r - responsobility matrix with probabilities\n",
    "plt.hist(clusters_prediction)\n",
    "plt.show()\n",
    "clusters_predicted_users = {float(database['idx2seq'][i]):cl for i, cl in enumerate(clusters_prediction)}\n",
    "df['clust_pred'] = df['id'].apply(lambda x: clusters_predicted_users[x])\n",
    "df.to_csv(f'{util.OUTPUT_DIR}/cluster_prediction_cluster{13}.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bb3126",
   "metadata": {},
   "source": [
    "### Purity calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354a981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tablesplots.get_metrics import purity\n",
    "df_gr = df.groupby(['file_name'], as_index=False)['clust_pred'].mean()\n",
    "df_gr.head()\n",
    "true_clust = pd.merge(true_clust, df_gr, on='file_name')\n",
    "true_clust.head()\n",
    "cl_pred = torch.Tensor(true_clust['clust_pred'].values)\n",
    "cl_true = torch.Tensor(true_clust['cluster_id'].values)\n",
    "purity(cl_true, cl_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
