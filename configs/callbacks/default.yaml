model_checkpoint:
    _target_: pytorch_lightning.callbacks.ModelCheckpoint
    monitor: "val_pur"      # name of the logged metric 
    save_top_k: 1           # save k best models 
    save_last: True         # additionaly save model from last epoch
    every_n_epochs: 5
    mode: "max"             # can be "max" or "min"
    verbose: True
    dirpath: ${save_dir}
    filename: '{epoch:02d}'


early_stopping:
    _target_: pytorch_lightning.callbacks.EarlyStopping
    monitor: "train_loss"      # name of the logged metric
    patience: 10           # num of not improving epochs until training stops
    mode: "min"             # can be "max" or "min"
    min_delta: 0            # min change in the logged metric to be qualified as an improvement
